model:
  enc:
    subsampling:
      num_blocks: 3
      num_layers_per_block: 2
      out_channels: [8,  16, 32]
      kernel_sizes: [3, 3, 3]
      strides: [1, 2, 2]
      residuals: [ True, True, True]
      dropout: 0.1 
    type: "conv-conformer"
    input_dim: 80
    encoder_dim: 256
    num_attention_heads: 8
    feed_forward_expansion_factor: 4
    dropout_rate: 0.1
    conv_kernel_size: 31
    num_encoder_layers: 1
    output_dim: 256
    in_channels: 1
    out_channels: 32
    conv_config:
      size: 256
      linear_units: 576
      fuse_type: "concat_fusion"
      kernel_sizes: "7, 15, 23, 31"
      merge_conv_kernel_size: 3
      use_non_linear: true
      use_linear_after_conv: true
      activation: "swish"
      gate_activation: "swish"
    name: "ConvConformer"
    projection_dim: 640
  dec: 
    n_layer: 1
    d_model: 256
    ff_size: 1024
    n_head: 4
    dropout: 0.1
    k: 3
  name: "ConvConformer"
  model_name: "ConvConformer"


training:
  epochs: 100
  batch_size: 8
  num_workers: 4
  save_path: "/home/anhkhoa/PhonoASR/saves"
  train_path : "/home/anhkhoa/transformer_transducer_speeQ/data/train_phoneme.json"
  dev_path : "/home/anhkhoa/transformer_transducer_speeQ/data/test_phoneme.json"
  test_path : "/home/anhkhoa/transformer_transducer_speeQ/data/test_phoneme.json"
  vocab_path : "/home/anhkhoa/transformer_transducer_speeQ/data/vocab_phoneme.json"
  logg : "/home/anhkhoa/TASA/logs/Conformer.log"
  reload: false
  max_grad_norm: 200
  result: "workspace/Conformer/result.txt"
  type: "normal"
  ctc_weight: 0.4
  type_training: "ce"


optim:
  type: "adam"
  lr: 0.001
  weight_decay: 0.0001
  decay_rate: 0.5


scheduler:
  lr_initial: 0.001
  n_warmup_steps: 10000


rnnt_loss:
  blank: 0
  reduction: "mean"
