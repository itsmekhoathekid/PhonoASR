model:
  enc: 
    n_head: 8
    input_dim: 80               
    d_model: 256       
    dropout: 0.2
    n_layer: 3
    type : 'SAA'
  dec: 
    type: 'base'
    n_layer: 3
    d_model: 256
    ff_size: 1024
    n_head: 4
    dropout: 0.1
    k: 3
  model_name: 'SAA-PHONEME'

training:
  epochs: 100
  patience: 15
  batch_size: 16
  save_path: "/datastore/npl/Speech2Text/PhonoASR/saves"
  train_path : "/datastore/npl/Speech2Text/dataset/LSVSC_train_phoneme.json"
  dev_path : "/datastore/npl/Speech2Text/dataset/LSVSC_valid_phoneme.json"
  test_path : "/datastore/npl/Speech2Text/dataset/LSVSC_test_phoneme.json"
  vocab_path : "/datastore/npl/Speech2Text/dataset/phoneme_vocab_lsvsc.json"
  wave_path: "/datastore/npl/Speech2Text/dataset/LSVSC_100/data"
  logg : "/datastore/npl/Speech2Text/PhonoASR/logs/ssa.log"
  result: "/datastore/npl/Speech2Text/PhonoASR/result-ssa-phoneme.txt"
  reload: False
  reload_mode: 'latest' # best/ latest
  ctc_weight: 0.4
  type_training: 'ce'
  type: 'word' # word/char/phoneme

infer: 
  type_decode: 'mtp_stack' # mtp_stack/mtp
optim:
  # type: sgd
  # lr: 0.0005
  # momentum: 0.9
  # weight_decay: 0
  # begin_to_adjust_lr: 60
  # nesterov: None
  # decay_rate: 0.5

  type: adam
  lr: 0.0003
  weight_decay: 0.0
  decay_rate: 0.5

scheduler:
  lr_initial: 0.0003
  n_warmup_steps: 15000

loss:


  