training:
  epochs: 100
  batch_size: 32
  num_workers: 4
  save_path: "/home/anhkhoa/PhonoASR/saves"
  train_path : "/home/anhkhoa/transformer_transducer_speeQ/data/train_phoneme.json"
  dev_path : "/home/anhkhoa/transformer_transducer_speeQ/data/test_phoneme.json"
  test_path : "/home/anhkhoa/transformer_transducer_speeQ/data/test_phoneme.json"
  vocab_path : "/home/anhkhoa/transformer_transducer_speeQ/data/vocab_phoneme.json"
  reload: False
  logg : "/home/anhkhoa/PhonoASR/logs/SpeechTransformer.log"
  ctc_weight: 0.3
  result: "/home/anhkhoa/PhonoASR/result_2.txt"
  type: "word"
  type_training : "ce"

  

optim:
  type: adam
  lr: 0.001
  weight_decay: 0.0001
  decay_rate: 0.5

scheduler:
  lr_initial: 0.001
  n_warmup_steps: 25000

model:
  enc:
    subsampling:
      num_blocks: 3
      num_layers_per_block: 1
      out_channels: [64, 64, 64]
      kernel_sizes: [5, 5, 1]
      strides: [2, 2, 1]
      residuals: [ False, False , True]
      dropout: 0.1 
    in_features: 1280
    n_layers: 12
    d_model: 512
    ff_size: 2048
    h: 4
    p_dropout: 0.1
    name: 'TASA'
  dec:
    n_layer: 6
    d_model: 512
    ff_size: 2048
    n_head: 4
    dropout: 0.1
    k: 3
  model_name: "TASA"


rnnt_loss:
  blank: 4
  reduction: "mean"  


