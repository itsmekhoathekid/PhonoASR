training:
  # epochs: 100
  batch_size: 32
  num_workers: 4
  save_path: /home/inomar01/nlp@uit/PhonoASR/saves
  train_path: /home/inomar01/nlp@uit/PhonoASR/data/LSVSC_train_char.json
  dev_path: /home/inomar01/nlp@uit/PhonoASR/data/LSVSC_valid_char.json
  test_path: /home/inomar01/nlp@uit/PhonoASR/data/LSVSC_test_char.json
  vocab_path: /home/inomar01/nlp@uit/PhonoASR/data/char_vocab_lsvsc.json
  wave_path: /home/inomar01/nlp@uit/PhonoASR/data/data
  logg: /home/inomar01/nlp@uit/PhonoASR/logs/vggtrans-char.log
  result: /home/inomar01/nlp@uit/PhonoASR/result-vgg-transformer-char.json
  reload: False
  reload_mode: 'best'
  ctc_weight: 0
  type: "char"
  type_training : "ce"

infer:
  type_decode: "normal"
  
optim:
  type: adam
  lr: 0.001
  weight_decay: 0.0001
  decay_rate: 0.5

scheduler:
  lr_initial: 0.001
  n_warmup_steps: 15000

model:
  enc:
    subsampling:
      num_blocks: 2
      out_channels: [32, 64]
      kernel_sizes: [3, 3]
      pooling_kernel_sizes: [2, 2]
      num_conv_layers : [2, 2]
      layer_norms: [True, True]
      dropout: 0.1
    input_dim : 80
    in_features: 1280
    n_layers: 8
    d_model: 256
    ff_size: 1024
    h: 4
    p_dropout: 0.1
    type: 'VGGTransformer'
  dec:
    type: 'vgg_dec'
    n_layers: 1
    d_model: 256
    ff_size: 1024
    n_head: 4
    dropout: 0.1
    k: 1
  model_name: "VGGTransformer-W2I"

rnnt_loss:
  blank: 4
  reduction: "mean"  
