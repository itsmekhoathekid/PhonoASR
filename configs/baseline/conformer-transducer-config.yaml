model:
  enc:
    subsampling:
      num_blocks: 3
      num_layers_per_block: 2
      out_channels: [8,  16, 32]
      kernel_sizes: [3, 3, 3]
      strides: [1, 2, 2]
      residuals: [ True, True, True]
      dropout: 0.1 
    input_dim: 80
    encoder_dim: 256
    d_model : 256
    num_attention_heads: 8
    feed_forward_expansion_factor : 4
    dropout_rate: 0.1
    conv_kernel_size: 31
    num_encoder_layers: 1
    output_dim: 256
    in_channels: 1
    out_channels: 32
    type : 'Conformer'
    projection_dim : 640
    output_dim : 320
  dec: 
    embedding_size: 256
    hidden_size: 512
    output_size: 320
    n_layers : 1
    type: "transducer"
    k: 1
  joint:
    input_size: 640
    inner_size: 512
  model_name : 'Conformer'
  k: 1

training:
    epochs: 100
    batch_size: 2
    num_workers: 4
    save_path: "workspace/PhonoASR/saves"
    train_path : "workspace/dataset/train_word.json"
    dev_path : "workspace/dataset/test_word.json"
    test_path : "workspace/dataset/test_word.json"
    vocab_path : "workspace/dataset/word_vocab_vivos.json"
    reload: False
    logg: "workspace/PhonoASR/logs/Conformer.log"
    # ctc_weight: 0.3
    result: "workspace/PhonoASR/result.txt"
    type: "word"
    type_training: "transducer"
    wave_path: "workspace/dataset/voices"

infer: 
    type_decode: "normal"
    
optim:
  type: adam
  lr: 0.001
  weight_decay: 0.0001
  decay_rate: 0.5

scheduler:
  lr_initial: 0.001
  n_warmup_steps: 15000

loss:
    blank: 5


  