model:
  enc:
    subsampling:
      num_blocks: 3
      num_layers_per_block: 2
      out_channels: [8,  16, 32]
      kernel_sizes: [3, 3, 3]
      strides: [1, 2, 2]
      residuals: [ True, True, True]
      dropout: 0.1 
    input_dim: 80
    encoder_dim: 256
    d_model: 256
    num_attention_heads: 8
    feed_forward_expansion_factor : 4
    dropout_rate: 0.1
    conv_kernel_size: 31
    num_encoder_layers: 8
    output_dim: 256
    in_channels: 1
    out_channels: 32
    name : 'Conformer'
    projection_dim : 640
  dec: 
    n_layer: 1
    d_model: 256
    ff_size: 1024
    n_head: 4
    dropout: 0.1
    k: 1
  model_name : 'Conformer'
  k: 1
  d_model: 256

training:
  batch_size: 32
  epochs: 100
  num_workers: 4  
  save_path: "/home/inomar01/nlp@uit/PhonoASR/saves"
  train_path : "/home/inomar01/nlp@uit/PhonoASR/dataset/LSVSC_train.json"
  dev_path : "/home/inomar01/nlp@uit/PhonoASR/dataset/LSVSC_valid.json"
  test_path : "/home/inomar01/nlp@uit/PhonoASR/dataset/LSVSC_test.json"
  vocab_path : "/home/inomar01/nlp@uit/PhonoASR/dataset/phoneme_vocab_lsvsc.json"
  wave_path: "/home/inomar01/nlp@uit/PhonoASR/dataset/LSVSC_100/data"
  logg : "/home/inomar01/nlp@uit/PhonoASR/logs/conformer.log"
  reload: False
  type: "word"
  ctc_weight: 0.4
  type_training: 'ctc-kldiv'
  sample_rate : 16000
  n_mels : 80
  n_fft : 512
  win_length : 25
  result: "/home/inomar01/nlp@uit/PhonoASR/word/result-conformer.json"

infer:
  type_decode: mtp_stack

optim:
  type: adam
  lr: 1
  weight_decay: 0.0001
  decay_rate: 0.5

scheduler:
  lr_initial: 1
  n_warmup_steps: 15000

loss:


  